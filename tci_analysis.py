#!/usr/bin/env python3
"""
Comprehensive TCI Analysis Script
Extracts and analyzes TCI scores from both Boids and Baseline experiments
"""

import json
import os
import glob
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import matplotlib.pyplot as plt
import seaborn as sns

def extract_tci_data(experiment_path: str) -> Dict[str, Any]:
    """Extract TCI data from all agents in an experiment."""
    
    experiment_data = {
        'experiment_name': os.path.basename(experiment_path),
        'agents': {},
        'all_tci_scores': [],
        'all_tools': [],
        'rounds_data': {},
        'pass_rates': {}
    }
    
    # Find all agent directories
    personal_tools_path = os.path.join(experiment_path, 'personal_tools')
    if not os.path.exists(personal_tools_path):
        return experiment_data
    
    agent_dirs = [d for d in os.listdir(personal_tools_path) 
                  if d.startswith('Agent_') and os.path.isdir(os.path.join(personal_tools_path, d))]
    
    for agent_dir in sorted(agent_dirs):
        agent_path = os.path.join(personal_tools_path, agent_dir)
        index_file = os.path.join(agent_path, 'index.json')
        
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r') as f:
                    agent_data = json.load(f)
                
                agent_info = {
                    'agent_id': agent_dir,
                    'tools': {},
                    'tci_scores': [],
                    'rounds': {},
                    'total_tools': 0,
                    'passed_tests': 0,
                    'total_tests': 0
                }
                
                for tool_name, tool_info in agent_data.get('tools', {}).items():
                    complexity = tool_info.get('complexity', {})
                    tci_score = complexity.get('tci_score', 0)
                    created_round = tool_info.get('created_in_round', 0)
                    test_passed = tool_info.get('test_passed', False)
                    
                    tool_data = {
                        'name': tool_name,
                        'tci_score': tci_score,
                        'code_complexity': complexity.get('code_complexity', 0),
                        'interface_complexity': complexity.get('interface_complexity', 0),
                        'compositional_complexity': complexity.get('compositional_complexity', 0),
                        'lines_of_code': complexity.get('lines_of_code', 0),
                        'param_count': complexity.get('param_count', 0),
                        'tool_calls': complexity.get('tool_calls', 0),
                        'external_imports': complexity.get('external_imports', 0),
                        'created_in_round': created_round,
                        'test_passed': test_passed,
                        'agent_id': agent_dir
                    }
                    
                    agent_info['tools'][tool_name] = tool_data
                    agent_info['tci_scores'].append(tci_score)
                    agent_info['total_tools'] += 1
                    agent_info['total_tests'] += 1
                    if test_passed:
                        agent_info['passed_tests'] += 1
                    
                    # Group by rounds
                    if created_round not in agent_info['rounds']:
                        agent_info['rounds'][created_round] = []
                    agent_info['rounds'][created_round].append(tool_data)
                    
                    # Add to experiment-wide data
                    experiment_data['all_tci_scores'].append(tci_score)
                    experiment_data['all_tools'].append(tool_data)
                    
                    # Group by rounds for experiment
                    if created_round not in experiment_data['rounds_data']:
                        experiment_data['rounds_data'][created_round] = []
                    experiment_data['rounds_data'][created_round].append(tool_data)
                
                experiment_data['agents'][agent_dir] = agent_info
                
            except Exception as e:
                print(f"Error processing {agent_dir}: {e}")
    
    return experiment_data

def calculate_statistics(tci_scores: List[float]) -> Dict[str, float]:
    """Calculate comprehensive statistics for TCI scores."""
    if not tci_scores:
        return {}
    
    scores = np.array(tci_scores)
    return {
        'mean': np.mean(scores),
        'median': np.median(scores),
        'std': np.std(scores),
        'min': np.min(scores),
        'max': np.max(scores),
        'q25': np.percentile(scores, 25),
        'q75': np.percentile(scores, 75),
        'count': len(scores),
        'sem': np.std(scores) / np.sqrt(len(scores))  # Standard error of mean
    }

def analyze_experiments():
    """Main analysis function."""
    
    # Experiment paths
    boids_path = "experiments/exp_boids_crocodile_conservation_intelligence_20250925_025019"
    baseline_path = "experiments/exp_global_crocodile_conservation_intelligence_20250925_024210"
    
    print("üîç COMPREHENSIVE TCI ANALYSIS")
    print("=" * 80)
    
    # Extract data
    print("üìä Extracting data from experiments...")
    boids_data = extract_tci_data(boids_path)
    baseline_data = extract_tci_data(baseline_path)
    
    print(f"‚úÖ Boids: {len(boids_data['agents'])} agents, {len(boids_data['all_tools'])} tools")
    print(f"‚úÖ Baseline: {len(baseline_data['agents'])} agents, {len(baseline_data['all_tools'])} tools")
    
    # Calculate statistics
    boids_stats = calculate_statistics(boids_data['all_tci_scores'])
    baseline_stats = calculate_statistics(baseline_data['all_tci_scores'])
    
    print("\nüìà TCI STATISTICS COMPARISON")
    print("=" * 80)
    
    # Main metrics table
    metrics = ['mean', 'std', 'min', 'max', 'median', 'count']
    print(f"{'Metric':<15} {'Boids':<12} {'Baseline':<12} {'Difference':<12} {'% Change':<10}")
    print("-" * 70)
    
    for metric in metrics:
        boids_val = boids_stats.get(metric, 0)
        baseline_val = baseline_stats.get(metric, 0)
        diff = boids_val - baseline_val
        pct_change = (diff / baseline_val * 100) if baseline_val != 0 else 0
        
        print(f"{metric:<15} {boids_val:<12.3f} {baseline_val:<12.3f} {diff:<12.3f} {pct_change:<10.2f}%")
    
    # Error bars (95% confidence interval)
    print(f"\nüìä ERROR BARS (95% Confidence Interval)")
    print("-" * 50)
    boids_ci = 1.96 * boids_stats['sem']
    baseline_ci = 1.96 * baseline_stats['sem']
    print(f"Boids:    {boids_stats['mean']:.3f} ¬± {boids_ci:.3f}")
    print(f"Baseline: {baseline_stats['mean']:.3f} ¬± {baseline_ci:.3f}")
    
    # Peak TCI Analysis
    print(f"\nüèÜ PEAK TCI ANALYSIS")
    print("=" * 50)
    
    boids_peak_tool = max(boids_data['all_tools'], key=lambda x: x['tci_score'])
    baseline_peak_tool = max(baseline_data['all_tools'], key=lambda x: x['tci_score'])
    
    print(f"üöÄ BOIDS PEAK:")
    print(f"   Tool: {boids_peak_tool['name']}")
    print(f"   Agent: {boids_peak_tool['agent_id']}")
    print(f"   TCI Score: {boids_peak_tool['tci_score']:.3f}")
    print(f"   Round: {boids_peak_tool['created_in_round']}")
    
    print(f"\n‚öñÔ∏è  BASELINE PEAK:")
    print(f"   Tool: {baseline_peak_tool['name']}")
    print(f"   Agent: {baseline_peak_tool['agent_id']}")
    print(f"   TCI Score: {baseline_peak_tool['tci_score']:.3f}")
    print(f"   Round: {baseline_peak_tool['created_in_round']}")
    
    peak_advantage = boids_peak_tool['tci_score'] - baseline_peak_tool['tci_score']
    peak_pct = (peak_advantage / baseline_peak_tool['tci_score']) * 100
    print(f"\nüéØ PEAK ADVANTAGE: +{peak_advantage:.3f} ({peak_pct:.1f}% higher)")
    
    # Last Round Analysis
    print(f"\nüèÅ LAST ROUND TCI ANALYSIS")
    print("=" * 50)
    
    # Find the last round for each experiment
    boids_last_round = max(boids_data['rounds_data'].keys()) if boids_data['rounds_data'] else 0
    baseline_last_round = max(baseline_data['rounds_data'].keys()) if baseline_data['rounds_data'] else 0
    
    boids_last_round_scores = [tool['tci_score'] for tool in boids_data['rounds_data'].get(boids_last_round, [])]
    baseline_last_round_scores = [tool['tci_score'] for tool in baseline_data['rounds_data'].get(baseline_last_round, [])]
    
    boids_last_stats = calculate_statistics(boids_last_round_scores)
    baseline_last_stats = calculate_statistics(baseline_last_round_scores)
    
    print(f"Boids Last Round ({boids_last_round}):    Mean TCI = {boids_last_stats.get('mean', 0):.3f} (n={len(boids_last_round_scores)})")
    print(f"Baseline Last Round ({baseline_last_round}): Mean TCI = {baseline_last_stats.get('mean', 0):.3f} (n={len(baseline_last_round_scores)})")
    
    last_round_diff = boids_last_stats.get('mean', 0) - baseline_last_stats.get('mean', 0)
    last_round_pct = (last_round_diff / baseline_last_stats.get('mean', 1)) * 100 if baseline_last_stats.get('mean', 0) != 0 else 0
    print(f"Last Round Advantage: +{last_round_diff:.3f} ({last_round_pct:.1f}% higher)")
    
    # Pass Rate Analysis
    print(f"\n‚úÖ TEST PASS RATE COMPARISON")
    print("=" * 50)
    
    boids_total_tests = sum(len(agent['tools']) for agent in boids_data['agents'].values())
    boids_passed_tests = sum(sum(1 for tool in agent['tools'].values() if tool['test_passed']) 
                            for agent in boids_data['agents'].values())
    
    baseline_total_tests = sum(len(agent['tools']) for agent in baseline_data['agents'].values())
    baseline_passed_tests = sum(sum(1 for tool in agent['tools'].values() if tool['test_passed']) 
                               for agent in baseline_data['agents'].values())
    
    boids_pass_rate = (boids_passed_tests / boids_total_tests) * 100 if boids_total_tests > 0 else 0
    baseline_pass_rate = (baseline_passed_tests / baseline_total_tests) * 100 if baseline_total_tests > 0 else 0
    
    print(f"Boids Pass Rate:    {boids_passed_tests}/{boids_total_tests} = {boids_pass_rate:.1f}%")
    print(f"Baseline Pass Rate: {baseline_passed_tests}/{baseline_total_tests} = {baseline_pass_rate:.1f}%")
    print(f"Pass Rate Difference: {boids_pass_rate - baseline_pass_rate:.1f} percentage points")
    
    # Detailed breakdown by complexity components
    print(f"\nüî¨ COMPLEXITY COMPONENT ANALYSIS")
    print("=" * 60)
    
    components = ['code_complexity', 'interface_complexity', 'compositional_complexity']
    
    print(f"{'Component':<25} {'Boids Mean':<12} {'Baseline Mean':<15} {'Difference':<12}")
    print("-" * 65)
    
    for component in components:
        boids_comp_scores = [tool[component] for tool in boids_data['all_tools']]
        baseline_comp_scores = [tool[component] for tool in baseline_data['all_tools']]
        
        boids_comp_mean = np.mean(boids_comp_scores) if boids_comp_scores else 0
        baseline_comp_mean = np.mean(baseline_comp_scores) if baseline_comp_scores else 0
        diff = boids_comp_mean - baseline_comp_mean
        
        print(f"{component:<25} {boids_comp_mean:<12.3f} {baseline_comp_mean:<15.3f} {diff:<12.3f}")
    
    # Round-by-round evolution
    print(f"\nüìà ROUND-BY-ROUND TCI EVOLUTION")
    print("=" * 50)
    
    all_rounds = sorted(set(list(boids_data['rounds_data'].keys()) + list(baseline_data['rounds_data'].keys())))
    
    print(f"{'Round':<8} {'Boids Mean':<12} {'Baseline Mean':<15} {'Difference':<12}")
    print("-" * 50)
    
    for round_num in all_rounds:
        boids_round_scores = [tool['tci_score'] for tool in boids_data['rounds_data'].get(round_num, [])]
        baseline_round_scores = [tool['tci_score'] for tool in baseline_data['rounds_data'].get(round_num, [])]
        
        boids_round_mean = np.mean(boids_round_scores) if boids_round_scores else 0
        baseline_round_mean = np.mean(baseline_round_scores) if baseline_round_scores else 0
        diff = boids_round_mean - baseline_round_mean
        
        print(f"{round_num:<8} {boids_round_mean:<12.3f} {baseline_round_mean:<15.3f} {diff:<12.3f}")
    
    # Summary
    print(f"\nüéâ FINAL SUMMARY")
    print("=" * 50)
    print(f"‚úÖ BOIDS WINS in Overall TCI: {boids_stats['mean']:.3f} vs {baseline_stats['mean']:.3f}")
    print(f"‚úÖ BOIDS WINS in Peak TCI: {boids_peak_tool['tci_score']:.3f} vs {baseline_peak_tool['tci_score']:.3f}")
    print(f"‚úÖ BOIDS WINS in Last Round: {boids_last_stats.get('mean', 0):.3f} vs {baseline_last_stats.get('mean', 0):.3f}")
    
    advantage_pct = ((boids_stats['mean'] - baseline_stats['mean']) / baseline_stats['mean']) * 100
    print(f"üöÄ Overall TCI Advantage: {advantage_pct:.1f}% higher than baseline")
    
    return {
        'boids_data': boids_data,
        'baseline_data': baseline_data,
        'boids_stats': boids_stats,
        'baseline_stats': baseline_stats,
        'boids_peak': boids_peak_tool,
        'baseline_peak': baseline_peak_tool
    }

if __name__ == "__main__":
    results = analyze_experiments()
